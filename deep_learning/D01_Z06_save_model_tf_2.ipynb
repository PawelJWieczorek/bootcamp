{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "print(tf.__version__)\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country wage_class  \n",
       "0          2174             0              40  United-States      <=50K  \n",
       "1             0             0              13  United-States      <=50K  \n",
       "2             0             0              40  United-States      <=50K  \n",
       "3             0             0              40  United-States      <=50K  \n",
       "4             0             0              40           Cuba      <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytaj dane treningowe i testowe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
    "test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
    "\n",
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']\n",
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels\n",
    "\n",
    "train = train_set.replace('?', np.nan).dropna()\n",
    "test = test_set.replace('?', np.nan).dropna()\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([train,test])\n",
    "\n",
    "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
    "\n",
    "dataset.drop([\"fnlwgt\"],axis=1,inplace=True)\n",
    "\n",
    "dataset.drop([\"education\"],axis=1,inplace=True)\n",
    "\n",
    "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
    "\n",
    "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
    "\n",
    "dataset['native_country'] = dataset['native_country'].replace(d)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "train = dataset.iloc[:train.shape[0]]\n",
    "test = dataset.iloc[train.shape[0]:]\n",
    "\n",
    "X_train = train.drop(\"wage_class\",axis=1)\n",
    "y_train = train.wage_class\n",
    "\n",
    "X_test = test.drop(\"wage_class\",axis=1)\n",
    "y_test = test.wage_class\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 100)               4200      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 9,771\n",
      "Trainable params: 9,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "929/943 [============================>.] - ETA: 0s - loss: 0.5472 - accuracy: 0.7514INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7523 - val_loss: 0.5171 - val_accuracy: 0.7908\n",
      "Epoch 2/100\n",
      "936/943 [============================>.] - ETA: 0s - loss: 0.5073 - accuracy: 0.7746INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.5073 - accuracy: 0.7745 - val_loss: 0.4904 - val_accuracy: 0.7773\n",
      "Epoch 3/100\n",
      "915/943 [============================>.] - ETA: 0s - loss: 0.4720 - accuracy: 0.7786INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.4711 - accuracy: 0.7790 - val_loss: 0.4453 - val_accuracy: 0.7823\n",
      "Epoch 4/100\n",
      "915/943 [============================>.] - ETA: 0s - loss: 0.4267 - accuracy: 0.7883INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.4260 - accuracy: 0.7889 - val_loss: 0.4048 - val_accuracy: 0.8035\n",
      "Epoch 5/100\n",
      "933/943 [============================>.] - ETA: 0s - loss: 0.3926 - accuracy: 0.8238INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3924 - accuracy: 0.8240 - val_loss: 0.3821 - val_accuracy: 0.8288\n",
      "Epoch 6/100\n",
      "904/943 [===========================>..] - ETA: 0s - loss: 0.3741 - accuracy: 0.8354INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3740 - accuracy: 0.8358 - val_loss: 0.3682 - val_accuracy: 0.8388\n",
      "Epoch 7/100\n",
      "914/943 [============================>.] - ETA: 0s - loss: 0.3647 - accuracy: 0.8378INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3635 - accuracy: 0.8387 - val_loss: 0.3590 - val_accuracy: 0.8369\n",
      "Epoch 8/100\n",
      "919/943 [============================>.] - ETA: 0s - loss: 0.3563 - accuracy: 0.8402INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3566 - accuracy: 0.8398 - val_loss: 0.3530 - val_accuracy: 0.8396\n",
      "Epoch 9/100\n",
      "938/943 [============================>.] - ETA: 0s - loss: 0.3518 - accuracy: 0.8409INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3516 - accuracy: 0.8411 - val_loss: 0.3499 - val_accuracy: 0.8367\n",
      "Epoch 10/100\n",
      "925/943 [============================>.] - ETA: 0s - loss: 0.3470 - accuracy: 0.8430INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3474 - accuracy: 0.8427 - val_loss: 0.3457 - val_accuracy: 0.8394\n",
      "Epoch 11/100\n",
      "922/943 [============================>.] - ETA: 0s - loss: 0.3454 - accuracy: 0.8432INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3450 - accuracy: 0.8433 - val_loss: 0.3446 - val_accuracy: 0.8432\n",
      "Epoch 12/100\n",
      "941/943 [============================>.] - ETA: 0s - loss: 0.3438 - accuracy: 0.8430INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3436 - accuracy: 0.8431 - val_loss: 0.3432 - val_accuracy: 0.8398\n",
      "Epoch 13/100\n",
      "887/943 [===========================>..] - ETA: 0s - loss: 0.3417 - accuracy: 0.8440INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3421 - accuracy: 0.8438 - val_loss: 0.3423 - val_accuracy: 0.8401\n",
      "Epoch 14/100\n",
      "935/943 [============================>.] - ETA: 0s - loss: 0.3407 - accuracy: 0.8430INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3409 - accuracy: 0.8427 - val_loss: 0.3400 - val_accuracy: 0.8439\n",
      "Epoch 15/100\n",
      "938/943 [============================>.] - ETA: 0s - loss: 0.3392 - accuracy: 0.8445INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3393 - accuracy: 0.8445 - val_loss: 0.3393 - val_accuracy: 0.8421\n",
      "Epoch 16/100\n",
      "922/943 [============================>.] - ETA: 0s - loss: 0.3374 - accuracy: 0.8455INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3375 - accuracy: 0.8456 - val_loss: 0.3361 - val_accuracy: 0.8461\n",
      "Epoch 17/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3365 - accuracy: 0.8460 - val_loss: 0.3364 - val_accuracy: 0.8416\n",
      "Epoch 18/100\n",
      "897/943 [===========================>..] - ETA: 0s - loss: 0.3348 - accuracy: 0.8478INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3354 - accuracy: 0.8471 - val_loss: 0.3359 - val_accuracy: 0.8413\n",
      "Epoch 19/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3349 - accuracy: 0.8459 - val_loss: 0.3383 - val_accuracy: 0.8396\n",
      "Epoch 20/100\n",
      "942/943 [============================>.] - ETA: 0s - loss: 0.3332 - accuracy: 0.8469INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.8468 - val_loss: 0.3336 - val_accuracy: 0.8441\n",
      "Epoch 21/100\n",
      "935/943 [============================>.] - ETA: 0s - loss: 0.3323 - accuracy: 0.8472INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3328 - accuracy: 0.8470 - val_loss: 0.3335 - val_accuracy: 0.8456\n",
      "Epoch 22/100\n",
      "928/943 [============================>.] - ETA: 0s - loss: 0.3328 - accuracy: 0.8462INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3324 - accuracy: 0.8466 - val_loss: 0.3326 - val_accuracy: 0.8455\n",
      "Epoch 23/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3319 - accuracy: 0.8474 - val_loss: 0.3333 - val_accuracy: 0.8428\n",
      "Epoch 24/100\n",
      "897/943 [===========================>..] - ETA: 0s - loss: 0.3314 - accuracy: 0.8471INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3314 - accuracy: 0.8469 - val_loss: 0.3320 - val_accuracy: 0.8442\n",
      "Epoch 25/100\n",
      "920/943 [============================>.] - ETA: 0s - loss: 0.3309 - accuracy: 0.8485INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3310 - accuracy: 0.8483 - val_loss: 0.3313 - val_accuracy: 0.8464\n",
      "Epoch 26/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3304 - accuracy: 0.8472 - val_loss: 0.3321 - val_accuracy: 0.8430\n",
      "Epoch 27/100\n",
      "940/943 [============================>.] - ETA: 0s - loss: 0.3300 - accuracy: 0.8473INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3301 - accuracy: 0.8472 - val_loss: 0.3302 - val_accuracy: 0.8486\n",
      "Epoch 28/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3285 - accuracy: 0.8481 - val_loss: 0.3304 - val_accuracy: 0.8446\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916/943 [============================>.] - ETA: 0s - loss: 0.3278 - accuracy: 0.8483INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3281 - accuracy: 0.8483 - val_loss: 0.3291 - val_accuracy: 0.8466\n",
      "Epoch 30/100\n",
      "899/943 [===========================>..] - ETA: 0s - loss: 0.3263 - accuracy: 0.8493INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3273 - accuracy: 0.8488 - val_loss: 0.3288 - val_accuracy: 0.8458\n",
      "Epoch 31/100\n",
      "922/943 [============================>.] - ETA: 0s - loss: 0.3276 - accuracy: 0.8489INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3272 - accuracy: 0.8489 - val_loss: 0.3284 - val_accuracy: 0.8470\n",
      "Epoch 32/100\n",
      "896/943 [===========================>..] - ETA: 0s - loss: 0.3275 - accuracy: 0.8486INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3269 - accuracy: 0.8490 - val_loss: 0.3284 - val_accuracy: 0.8459\n",
      "Epoch 33/100\n",
      "886/943 [===========================>..] - ETA: 0s - loss: 0.3264 - accuracy: 0.8485INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3267 - accuracy: 0.8486 - val_loss: 0.3283 - val_accuracy: 0.8483\n",
      "Epoch 34/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3265 - accuracy: 0.8486 - val_loss: 0.3298 - val_accuracy: 0.8455\n",
      "Epoch 35/100\n",
      "941/943 [============================>.] - ETA: 0s - loss: 0.3267 - accuracy: 0.8486INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3265 - accuracy: 0.8487 - val_loss: 0.3279 - val_accuracy: 0.8469\n",
      "Epoch 36/100\n",
      "906/943 [===========================>..] - ETA: 0s - loss: 0.3270 - accuracy: 0.8482INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3263 - accuracy: 0.8484 - val_loss: 0.3278 - val_accuracy: 0.8493\n",
      "Epoch 37/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3260 - accuracy: 0.8486 - val_loss: 0.3278 - val_accuracy: 0.8465\n",
      "Epoch 38/100\n",
      "926/943 [============================>.] - ETA: 0s - loss: 0.3258 - accuracy: 0.8488INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3258 - accuracy: 0.8489 - val_loss: 0.3276 - val_accuracy: 0.8482\n",
      "Epoch 39/100\n",
      "936/943 [============================>.] - ETA: 0s - loss: 0.3255 - accuracy: 0.8492INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 4s 4ms/step - loss: 0.3257 - accuracy: 0.8490 - val_loss: 0.3274 - val_accuracy: 0.8469\n",
      "Epoch 40/100\n",
      "941/943 [============================>.] - ETA: 0s - loss: 0.3256 - accuracy: 0.8485INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3253 - accuracy: 0.8487 - val_loss: 0.3273 - val_accuracy: 0.8467\n",
      "Epoch 41/100\n",
      "906/943 [===========================>..] - ETA: 0s - loss: 0.3260 - accuracy: 0.8492INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3253 - accuracy: 0.8499 - val_loss: 0.3271 - val_accuracy: 0.8471\n",
      "Epoch 42/100\n",
      "939/943 [============================>.] - ETA: 0s - loss: 0.3250 - accuracy: 0.8489INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3251 - accuracy: 0.8489 - val_loss: 0.3269 - val_accuracy: 0.8473\n",
      "Epoch 43/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3251 - accuracy: 0.8497 - val_loss: 0.3269 - val_accuracy: 0.8473\n",
      "Epoch 44/100\n",
      "921/943 [============================>.] - ETA: 0s - loss: 0.3255 - accuracy: 0.8494INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3250 - accuracy: 0.8496 - val_loss: 0.3268 - val_accuracy: 0.8475\n",
      "Epoch 45/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3249 - accuracy: 0.8494 - val_loss: 0.3269 - val_accuracy: 0.8461\n",
      "Epoch 46/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3248 - accuracy: 0.8495 - val_loss: 0.3269 - val_accuracy: 0.8475\n",
      "Epoch 47/100\n",
      "925/943 [============================>.] - ETA: 0s - loss: 0.3244 - accuracy: 0.8497INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 5s 5ms/step - loss: 0.3247 - accuracy: 0.8497 - val_loss: 0.3266 - val_accuracy: 0.8469\n",
      "Epoch 48/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3248 - accuracy: 0.8494 - val_loss: 0.3271 - val_accuracy: 0.8475\n",
      "Epoch 49/100\n",
      "928/943 [============================>.] - ETA: 0s - loss: 0.3247 - accuracy: 0.8498INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 4s 4ms/step - loss: 0.3246 - accuracy: 0.8499 - val_loss: 0.3266 - val_accuracy: 0.8477\n",
      "Epoch 50/100\n",
      "925/943 [============================>.] - ETA: 0s - loss: 0.3244 - accuracy: 0.8498INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 3s 4ms/step - loss: 0.3244 - accuracy: 0.8498 - val_loss: 0.3265 - val_accuracy: 0.8469\n",
      "Epoch 51/100\n",
      "936/943 [============================>.] - ETA: 0s - loss: 0.3246 - accuracy: 0.8496INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3244 - accuracy: 0.8497 - val_loss: 0.3265 - val_accuracy: 0.8472\n",
      "Epoch 52/100\n",
      "941/943 [============================>.] - ETA: 0s - loss: 0.3240 - accuracy: 0.8494INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3243 - accuracy: 0.8493 - val_loss: 0.3265 - val_accuracy: 0.8469\n",
      "Epoch 53/100\n",
      "908/943 [===========================>..] - ETA: 0s - loss: 0.3239 - accuracy: 0.8506INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3243 - accuracy: 0.8501 - val_loss: 0.3264 - val_accuracy: 0.8473\n",
      "Epoch 54/100\n",
      "933/943 [============================>.] - ETA: 0s - loss: 0.3240 - accuracy: 0.8501INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3243 - accuracy: 0.8499 - val_loss: 0.3263 - val_accuracy: 0.8470\n",
      "Epoch 55/100\n",
      "931/943 [============================>.] - ETA: 0s - loss: 0.3239 - accuracy: 0.8501INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3243 - accuracy: 0.8497 - val_loss: 0.3263 - val_accuracy: 0.8470\n",
      "Epoch 56/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3242 - accuracy: 0.8497 - val_loss: 0.3263 - val_accuracy: 0.8472\n",
      "Epoch 57/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3242 - accuracy: 0.8493 - val_loss: 0.3263 - val_accuracy: 0.8471\n",
      "Epoch 58/100\n",
      "931/943 [============================>.] - ETA: 0s - loss: 0.3237 - accuracy: 0.8501INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3241 - accuracy: 0.8498 - val_loss: 0.3262 - val_accuracy: 0.8470\n",
      "Epoch 59/100\n",
      "914/943 [============================>.] - ETA: 0s - loss: 0.3236 - accuracy: 0.8496INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3241 - accuracy: 0.8495 - val_loss: 0.3262 - val_accuracy: 0.8472\n",
      "Epoch 60/100\n",
      "929/943 [============================>.] - ETA: 0s - loss: 0.3240 - accuracy: 0.8494INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3240 - accuracy: 0.8497 - val_loss: 0.3261 - val_accuracy: 0.8473\n",
      "Epoch 61/100\n",
      "909/943 [===========================>..] - ETA: 0s - loss: 0.3241 - accuracy: 0.8496INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3240 - accuracy: 0.8499 - val_loss: 0.3261 - val_accuracy: 0.8471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3239 - accuracy: 0.8494 - val_loss: 0.3262 - val_accuracy: 0.8473\n",
      "Epoch 63/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3239 - accuracy: 0.8497 - val_loss: 0.3261 - val_accuracy: 0.8471\n",
      "Epoch 64/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3239 - accuracy: 0.8499 - val_loss: 0.3262 - val_accuracy: 0.8471\n",
      "Epoch 65/100\n",
      "895/943 [===========================>..] - ETA: 0s - loss: 0.3233 - accuracy: 0.8504INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3239 - accuracy: 0.8499 - val_loss: 0.3261 - val_accuracy: 0.8473\n",
      "Epoch 66/100\n",
      "917/943 [============================>.] - ETA: 0s - loss: 0.3239 - accuracy: 0.8495INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3239 - accuracy: 0.8498 - val_loss: 0.3261 - val_accuracy: 0.8475\n",
      "Epoch 67/100\n",
      "908/943 [===========================>..] - ETA: 0s - loss: 0.3244 - accuracy: 0.8492INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3238 - accuracy: 0.8494 - val_loss: 0.3260 - val_accuracy: 0.8475\n",
      "Epoch 68/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3238 - accuracy: 0.8498 - val_loss: 0.3261 - val_accuracy: 0.8473\n",
      "Epoch 69/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3238 - accuracy: 0.8498 - val_loss: 0.3260 - val_accuracy: 0.8473\n",
      "Epoch 70/100\n",
      "905/943 [===========================>..] - ETA: 0s - loss: 0.3231 - accuracy: 0.8502INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3238 - accuracy: 0.8500 - val_loss: 0.3260 - val_accuracy: 0.8472\n",
      "Epoch 71/100\n",
      "933/943 [============================>.] - ETA: 0s - loss: 0.3234 - accuracy: 0.8499INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3237 - accuracy: 0.8498 - val_loss: 0.3260 - val_accuracy: 0.8473\n",
      "Epoch 72/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3237 - accuracy: 0.8497 - val_loss: 0.3260 - val_accuracy: 0.8473\n",
      "Epoch 73/100\n",
      "939/943 [============================>.] - ETA: 0s - loss: 0.3237 - accuracy: 0.8498INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3237 - accuracy: 0.8498 - val_loss: 0.3260 - val_accuracy: 0.8472\n",
      "Epoch 74/100\n",
      "942/943 [============================>.] - ETA: 0s - loss: 0.3238 - accuracy: 0.8497INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3237 - accuracy: 0.8497 - val_loss: 0.3260 - val_accuracy: 0.8475\n",
      "Epoch 75/100\n",
      "918/943 [============================>.] - ETA: 0s - loss: 0.3241 - accuracy: 0.8494INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3237 - accuracy: 0.8497 - val_loss: 0.3260 - val_accuracy: 0.8475\n",
      "Epoch 76/100\n",
      "905/943 [===========================>..] - ETA: 0s - loss: 0.3240 - accuracy: 0.8495INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3237 - accuracy: 0.8498 - val_loss: 0.3259 - val_accuracy: 0.8473\n",
      "Epoch 77/100\n",
      "914/943 [============================>.] - ETA: 0s - loss: 0.3236 - accuracy: 0.8499INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3237 - accuracy: 0.8499 - val_loss: 0.3259 - val_accuracy: 0.8473\n",
      "Epoch 78/100\n",
      "901/943 [===========================>..] - ETA: 0s - loss: 0.3244 - accuracy: 0.8488INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3237 - accuracy: 0.8497 - val_loss: 0.3259 - val_accuracy: 0.8473\n",
      "Epoch 79/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3237 - accuracy: 0.8497 - val_loss: 0.3259 - val_accuracy: 0.8475\n",
      "Epoch 80/100\n",
      "939/943 [============================>.] - ETA: 0s - loss: 0.3237 - accuracy: 0.8495INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3236 - accuracy: 0.8497 - val_loss: 0.3259 - val_accuracy: 0.8473\n",
      "Epoch 81/100\n",
      "910/943 [===========================>..] - ETA: 0s - loss: 0.3235 - accuracy: 0.8499INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3236 - accuracy: 0.8498 - val_loss: 0.3259 - val_accuracy: 0.8473\n",
      "Epoch 82/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3236 - accuracy: 0.8497 - val_loss: 0.3259 - val_accuracy: 0.8472\n",
      "Epoch 83/100\n",
      "917/943 [============================>.] - ETA: 0s - loss: 0.3239 - accuracy: 0.8496INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3236 - accuracy: 0.8500 - val_loss: 0.3259 - val_accuracy: 0.8474\n",
      "Epoch 84/100\n",
      "911/943 [===========================>..] - ETA: 0s - loss: 0.3234 - accuracy: 0.8500INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3236 - accuracy: 0.8498 - val_loss: 0.3259 - val_accuracy: 0.8476\n",
      "Epoch 85/100\n",
      "897/943 [===========================>..] - ETA: 0s - loss: 0.3236 - accuracy: 0.8503INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3236 - accuracy: 0.8500 - val_loss: 0.3259 - val_accuracy: 0.8474\n",
      "Epoch 86/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3236 - accuracy: 0.8498 - val_loss: 0.3259 - val_accuracy: 0.8473\n",
      "Epoch 87/100\n",
      "894/943 [===========================>..] - ETA: 0s - loss: 0.3231 - accuracy: 0.8504INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3236 - accuracy: 0.8499 - val_loss: 0.3259 - val_accuracy: 0.8473\n",
      "Epoch 88/100\n",
      "943/943 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8496 - val_loss: 0.3259 - val_accuracy: 0.8472\n",
      "Epoch 89/100\n",
      "895/943 [===========================>..] - ETA: 0s - loss: 0.3230 - accuracy: 0.8505INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3236 - accuracy: 0.8498 - val_loss: 0.3259 - val_accuracy: 0.8473\n",
      "Epoch 90/100\n",
      "924/943 [============================>.] - ETA: 0s - loss: 0.3239 - accuracy: 0.8495INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3236 - accuracy: 0.8498 - val_loss: 0.3259 - val_accuracy: 0.8473\n",
      "Epoch 91/100\n",
      "914/943 [============================>.] - ETA: 0s - loss: 0.3242 - accuracy: 0.8498INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3236 - accuracy: 0.8499 - val_loss: 0.3259 - val_accuracy: 0.8472\n",
      "Epoch 92/100\n",
      "924/943 [============================>.] - ETA: 0s - loss: 0.3237 - accuracy: 0.8499INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3236 - accuracy: 0.8499 - val_loss: 0.3259 - val_accuracy: 0.8473\n",
      "Epoch 93/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3236 - accuracy: 0.8500 - val_loss: 0.3259 - val_accuracy: 0.8473\n",
      "Epoch 94/100\n",
      "934/943 [============================>.] - ETA: 0s - loss: 0.3233 - accuracy: 0.8501INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3236 - accuracy: 0.8498 - val_loss: 0.3259 - val_accuracy: 0.8473\n",
      "Epoch 95/100\n",
      "941/943 [============================>.] - ETA: 0s - loss: 0.3236 - accuracy: 0.8501INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3236 - accuracy: 0.8501 - val_loss: 0.3259 - val_accuracy: 0.8474\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3236 - accuracy: 0.8499 - val_loss: 0.3259 - val_accuracy: 0.8473\n",
      "Epoch 97/100\n",
      "924/943 [============================>.] - ETA: 0s - loss: 0.3231 - accuracy: 0.8502INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3236 - accuracy: 0.8498 - val_loss: 0.3259 - val_accuracy: 0.8474\n",
      "Epoch 98/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3236 - accuracy: 0.8499 - val_loss: 0.3259 - val_accuracy: 0.8473\n",
      "Epoch 99/100\n",
      "923/943 [============================>.] - ETA: 0s - loss: 0.3234 - accuracy: 0.8498INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3236 - accuracy: 0.8499 - val_loss: 0.3259 - val_accuracy: 0.8473\n",
      "Epoch 100/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3235 - accuracy: 0.8499 - val_loss: 0.3259 - val_accuracy: 0.8473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xa88675c748>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.callbacks import History\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "history_Adam = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation=\"sigmoid\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(50,activation=\"sigmoid\"))\n",
    "model.add(Dense(10,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "Adam = keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=Adam, metrics=[\"accuracy\"])\n",
    "\n",
    "save_best_model = ModelCheckpoint(\"wagi_best.h5py\",save_best_only=True)\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100, callbacks=[lrate, history_Adam, save_best_model])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['accuracy'], label = \"tarina Adam 0.0001 LR\")\n",
    "plt.plot(history_Adam.history['val_accuracy'], label = \"test Adam 0.0001 LR\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a02c9e994674>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2202\u001b[0m           'first, then load the weights.')\n\u001b[0;32m   2203\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2204\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2205\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2206\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"wagi_best.h5py\")\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Zapisz 3 modele z różnymi parametrami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
