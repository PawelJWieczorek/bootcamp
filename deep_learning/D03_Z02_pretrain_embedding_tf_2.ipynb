{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "print(tf.__version__)\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, SimpleRNN, LSTM, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import History\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Embedding layer is defined as the first hidden layer of a network. It must specify 3 arguments:\n",
    "\n",
    "It must specify 3 arguments:\n",
    "\n",
    "* **input_dim**: This is the size of the vocabulary in the text data. For example, if your data is integer encoded to values between 0-10, then the size of the vocabulary would be 11 words.\n",
    "* **output_dim**: This is the size of the vector space in which words will be embedded. It defines the size of the output vectors from this layer for each word. For example, it could be 32 or 100 or even larger. Test different values for your problem.\n",
    "* **input_length**: This is the length of input sequences, as you would define for any input layer of a Keras model. For example, if all of your input documents are comprised of 1000 words, this would be 1000.\n",
    "\n",
    "# Zad. \n",
    "Podążamy za stroną: \n",
    "\n",
    "https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "\n",
    "mamy jakiś zbiór tekstów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "    'Good work',\n",
    "    'Great effort',\n",
    "    'nice work',\n",
    "    'Excellent!',\n",
    "    'Weak',\n",
    "    'Poor effort!',\n",
    "    'not good',\n",
    "    'poor work',\n",
    "    'Could have done better.']\n",
    "# define class labels\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do warstwy **Embedding layer** wchodzi sekwencja intów.\n",
    "\n",
    "* my wykorzystamy reprezenatację Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33, 18], [38, 23], [25, 47], [48, 23], [7], [17], [20, 47], [13, 38], [20, 23], [13, 15, 18, 46]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekwencje mają różne długości, a Keras wymaga aby wejścia były równej długość."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33 18  0  0]\n",
      " [38 23  0  0]\n",
      " [25 47  0  0]\n",
      " [48 23  0  0]\n",
      " [ 7  0  0  0]\n",
      " [17  0  0  0]\n",
      " [20 47  0  0]\n",
      " [13 38  0  0]\n",
      " [20 23  0  0]\n",
      " [13 15 18 46]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Embeding ma rakres 50 i długość wejściową 4. Zmniejszmy embending do wymiaru 8.\n",
    "* Model jest prostym klasyfikatorem binarnym. \n",
    "* Co ważne, wynik z warstwy Embeding będzie wynosił 4 wektory o 8 wymiarach każdy, po jednym dla każdego słowa. \n",
    "* Spłaszczamy to do jednego 32-elementowego wektora, aby przejść do warstwy wyjściowej Dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "history_1 = History()\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.6884 - accuracy: 0.7778 - val_loss: 0.6504 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6875 - accuracy: 0.7778 - val_loss: 0.6499 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6865 - accuracy: 0.7778 - val_loss: 0.6494 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6855 - accuracy: 0.7778 - val_loss: 0.6488 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6846 - accuracy: 0.6667 - val_loss: 0.6483 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6836 - accuracy: 0.7778 - val_loss: 0.6478 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6826 - accuracy: 0.7778 - val_loss: 0.6472 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6816 - accuracy: 0.7778 - val_loss: 0.6467 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6806 - accuracy: 0.7778 - val_loss: 0.6461 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6796 - accuracy: 0.7778 - val_loss: 0.6455 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6786 - accuracy: 0.7778 - val_loss: 0.6450 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6776 - accuracy: 0.7778 - val_loss: 0.6444 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6766 - accuracy: 0.7778 - val_loss: 0.6437 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6756 - accuracy: 0.7778 - val_loss: 0.6431 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6746 - accuracy: 0.7778 - val_loss: 0.6425 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6735 - accuracy: 0.7778 - val_loss: 0.6418 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6725 - accuracy: 0.7778 - val_loss: 0.6412 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6715 - accuracy: 0.7778 - val_loss: 0.6405 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6704 - accuracy: 0.7778 - val_loss: 0.6398 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6693 - accuracy: 0.7778 - val_loss: 0.6391 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6683 - accuracy: 0.7778 - val_loss: 0.6384 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6672 - accuracy: 0.7778 - val_loss: 0.6376 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6661 - accuracy: 0.7778 - val_loss: 0.6369 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6650 - accuracy: 0.7778 - val_loss: 0.6361 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6639 - accuracy: 0.7778 - val_loss: 0.6353 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6628 - accuracy: 0.7778 - val_loss: 0.6345 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6617 - accuracy: 0.7778 - val_loss: 0.6337 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6605 - accuracy: 0.7778 - val_loss: 0.6329 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6594 - accuracy: 0.7778 - val_loss: 0.6321 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6582 - accuracy: 0.7778 - val_loss: 0.6312 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6571 - accuracy: 0.7778 - val_loss: 0.6304 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6559 - accuracy: 0.7778 - val_loss: 0.6295 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6547 - accuracy: 0.7778 - val_loss: 0.6286 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6535 - accuracy: 0.7778 - val_loss: 0.6277 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6523 - accuracy: 0.7778 - val_loss: 0.6267 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6510 - accuracy: 0.7778 - val_loss: 0.6258 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6498 - accuracy: 0.7778 - val_loss: 0.6248 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6486 - accuracy: 0.7778 - val_loss: 0.6239 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6473 - accuracy: 0.7778 - val_loss: 0.6229 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6460 - accuracy: 0.7778 - val_loss: 0.6219 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6448 - accuracy: 0.7778 - val_loss: 0.6209 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6435 - accuracy: 0.7778 - val_loss: 0.6198 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6422 - accuracy: 0.7778 - val_loss: 0.6188 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6408 - accuracy: 0.7778 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6395 - accuracy: 0.7778 - val_loss: 0.6166 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6382 - accuracy: 0.7778 - val_loss: 0.6155 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6368 - accuracy: 0.7778 - val_loss: 0.6144 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6355 - accuracy: 0.7778 - val_loss: 0.6133 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6341 - accuracy: 0.7778 - val_loss: 0.6121 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6327 - accuracy: 0.7778 - val_loss: 0.6109 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6313 - accuracy: 0.7778 - val_loss: 0.6097 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6299 - accuracy: 0.7778 - val_loss: 0.6085 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6285 - accuracy: 0.7778 - val_loss: 0.6073 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6270 - accuracy: 0.7778 - val_loss: 0.6061 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6256 - accuracy: 0.7778 - val_loss: 0.6048 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6241 - accuracy: 0.7778 - val_loss: 0.6035 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6227 - accuracy: 0.7778 - val_loss: 0.6022 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6212 - accuracy: 0.7778 - val_loss: 0.6009 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6197 - accuracy: 0.7778 - val_loss: 0.5996 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6182 - accuracy: 0.8889 - val_loss: 0.5983 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6167 - accuracy: 0.8889 - val_loss: 0.5969 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6151 - accuracy: 0.8889 - val_loss: 0.5955 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6136 - accuracy: 0.8889 - val_loss: 0.5941 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6121 - accuracy: 0.8889 - val_loss: 0.5927 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6105 - accuracy: 0.8889 - val_loss: 0.5913 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6089 - accuracy: 0.8889 - val_loss: 0.5898 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6073 - accuracy: 0.8889 - val_loss: 0.5884 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6058 - accuracy: 0.8889 - val_loss: 0.5869 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6041 - accuracy: 0.8889 - val_loss: 0.5854 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6025 - accuracy: 0.8889 - val_loss: 0.5839 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6009 - accuracy: 0.8889 - val_loss: 0.5823 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5993 - accuracy: 0.8889 - val_loss: 0.5808 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5976 - accuracy: 0.8889 - val_loss: 0.5792 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5960 - accuracy: 0.8889 - val_loss: 0.5776 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5943 - accuracy: 0.8889 - val_loss: 0.5760 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5926 - accuracy: 0.8889 - val_loss: 0.5744 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5910 - accuracy: 0.8889 - val_loss: 0.5728 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5893 - accuracy: 0.8889 - val_loss: 0.5711 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5876 - accuracy: 0.8889 - val_loss: 0.5694 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5858 - accuracy: 0.8889 - val_loss: 0.5678 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5841 - accuracy: 0.8889 - val_loss: 0.5661 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5824 - accuracy: 0.8889 - val_loss: 0.5644 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5807 - accuracy: 0.8889 - val_loss: 0.5626 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5789 - accuracy: 0.8889 - val_loss: 0.5609 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5771 - accuracy: 0.8889 - val_loss: 0.5591 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5754 - accuracy: 0.8889 - val_loss: 0.5574 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5736 - accuracy: 0.8889 - val_loss: 0.5556 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5718 - accuracy: 0.8889 - val_loss: 0.5538 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5700 - accuracy: 0.8889 - val_loss: 0.5520 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5682 - accuracy: 0.8889 - val_loss: 0.5502 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5664 - accuracy: 0.8889 - val_loss: 0.5483 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5646 - accuracy: 0.8889 - val_loss: 0.5465 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5627 - accuracy: 0.8889 - val_loss: 0.5446 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5609 - accuracy: 0.8889 - val_loss: 0.5428 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5591 - accuracy: 0.8889 - val_loss: 0.5409 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5572 - accuracy: 0.8889 - val_loss: 0.5390 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5553 - accuracy: 0.8889 - val_loss: 0.5371 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5535 - accuracy: 0.8889 - val_loss: 0.5352 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5516 - accuracy: 0.8889 - val_loss: 0.5333 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5497 - accuracy: 0.8889 - val_loss: 0.5314 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x4430364548>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# # fit the model\n",
    "# model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(padded_docs, labels, epochs=100, validation_split=0.1, callbacks=[history_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.999998\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_1.history['accuracy'], label = \"tarina Adam\")\n",
    "plt.plot(history_1.history['val_accuracy'], label = \"test Adam\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain embedding\n",
    "\n",
    "https://keras.io/examples/nlp/pretrained_word_embeddings/\n",
    "\n",
    "* GloVe embedding data can be found at: http://nlp.stanford.edu/data/glove.6B.zip (source page: http://nlp.stanford.edu/projects/glove/)\n",
    "\n",
    "* After downloading and unzipping, you will see a few files, one of which is “glove.6B.50d.txt“, which contains a 100-dimensional version of the embedding.\n",
    "\n",
    "\n",
    "Pojedyńczy plik można pobrać z tąd:\n",
    "https://www.dropbox.com/sh/tjq47ybybgnrbel/AAAVbp0UkQTAbKWVMIi5mtHpa?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = ''\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, 'glove.6B.50d')\n",
    "\n",
    "# first, build index mapping words in the embeddings set\n",
    "# to their embedding vector\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "# file = open(filename, encoding=\"utf8\")\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.50d.txt'), encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
    "        embeddings_index[word] = coefs\n",
    "        \n",
    "\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.1891e-01,  1.5255e-01, -8.2073e-02, -7.4144e-01,  7.5917e-01,\n",
       "       -4.8328e-01, -3.1009e-01,  5.1476e-01, -9.8708e-01,  6.1757e-04,\n",
       "       -1.5043e-01,  8.3770e-01, -1.0797e+00, -5.1460e-01,  1.3188e+00,\n",
       "        6.2007e-01,  1.3779e-01,  4.7108e-01, -7.2874e-02, -7.2675e-01,\n",
       "       -7.4116e-01,  7.5263e-01,  8.8180e-01,  2.9561e-01,  1.3548e+00,\n",
       "       -2.5701e+00, -1.3523e+00,  4.5880e-01,  1.0068e+00, -1.1856e+00,\n",
       "        3.4737e+00,  7.7898e-01, -7.2929e-01,  2.5102e-01, -2.6156e-01,\n",
       "       -3.4684e-01,  5.5841e-01,  7.5098e-01,  4.9830e-01, -2.6823e-01,\n",
       "       -2.7443e-03, -1.8298e-02, -2.8096e-01,  5.5318e-01,  3.7706e-02,\n",
       "        1.8555e-01, -1.5025e-01, -5.7512e-01, -2.6671e-01,  9.2121e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index[\"i\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better.']\n",
    "# define class labels\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides a Tokenizer class that can be fit on the training data, can convert text to sequences consistently by calling the texts_to_sequences() method on the Tokenizer class, and provides access to the dictionary mapping of words to integers in a word_index attribute.\n",
    "\n",
    "https://keras.io/preprocessing/text/#tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekwencje mają różne długości, a Keras wymaga aby wejścia były równej długość."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  2  0  0]\n",
      " [ 3  1  0  0]\n",
      " [ 7  4  0  0]\n",
      " [ 8  1  0  0]\n",
      " [ 9  0  0  0]\n",
      " [10  0  0  0]\n",
      " [ 5  4  0  0]\n",
      " [11  3  0  0]\n",
      " [ 5  1  0  0]\n",
      " [12 13  2 14]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to create a matrix of one embedding for each word in the training dataset. We can do that by enumerating all unique words in the Tokenizer.word_index and locating the embedding weight vector from the loaded GloVe embedding.\n",
    "\n",
    "The result is a matrix of weights only for words we will see during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 50)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 50))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "embedding_matrix.shape        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.13589978e-01,  1.96950004e-01, -5.19439995e-01, -8.62179995e-01,\n",
       "        1.54940002e-02,  1.09729998e-01, -8.02929997e-01, -3.33609998e-01,\n",
       "       -1.61189993e-04,  1.01889996e-02,  4.67340015e-02,  4.67510015e-01,\n",
       "       -4.74750012e-01,  1.10380001e-01,  3.93269986e-01, -4.36520010e-01,\n",
       "        3.99839997e-01,  2.71090001e-01,  4.26499993e-01, -6.06400013e-01,\n",
       "        8.11450005e-01,  4.56299990e-01, -1.27260000e-01, -2.24739999e-01,\n",
       "        6.40709996e-01, -1.27670002e+00, -7.22310007e-01, -6.95900023e-01,\n",
       "        2.80450005e-02, -2.30719998e-01,  3.79959989e+00, -1.26249999e-01,\n",
       "       -4.79669988e-01, -9.99719977e-01, -2.19760001e-01,  5.05649984e-01,\n",
       "        2.59530004e-02,  8.05140018e-01,  1.99290007e-01,  2.87959993e-01,\n",
       "       -1.59150004e-01, -3.04380000e-01,  1.60249993e-01, -1.82899997e-01,\n",
       "       -3.85629982e-02, -1.76190004e-01,  2.70409994e-02,  4.68420014e-02,\n",
       "       -6.28970027e-01,  3.57259989e-01])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.13589978e-01,  1.96950004e-01, -5.19439995e-01, -8.62179995e-01,\n",
       "        1.54940002e-02,  1.09729998e-01, -8.02929997e-01, -3.33609998e-01,\n",
       "       -1.61189993e-04,  1.01889996e-02,  4.67340015e-02,  4.67510015e-01,\n",
       "       -4.74750012e-01,  1.10380001e-01,  3.93269986e-01, -4.36520010e-01,\n",
       "        3.99839997e-01,  2.71090001e-01,  4.26499993e-01, -6.06400013e-01,\n",
       "        8.11450005e-01,  4.56299990e-01, -1.27260000e-01, -2.24739999e-01,\n",
       "        6.40709996e-01, -1.27670002e+00, -7.22310007e-01, -6.95900023e-01,\n",
       "        2.80450005e-02, -2.30719998e-01,  3.79959989e+00, -1.26249999e-01,\n",
       "       -4.79669988e-01, -9.99719977e-01, -2.19760001e-01,  5.05649984e-01,\n",
       "        2.59530004e-02,  8.05140018e-01,  1.99290007e-01,  2.87959993e-01,\n",
       "       -1.59150004e-01, -3.04380000e-01,  1.60249993e-01, -1.82899997e-01,\n",
       "       -3.85629982e-02, -1.76190004e-01,  2.70409994e-02,  4.68420014e-02,\n",
       "       -6.28970027e-01,  3.57259989e-01])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key difference is that the embedding layer can be seeded with the GloVe word embedding weights. We chose the 50-dimensional version, therefore the Embedding layer must be defined with output_dim set to 50. Finally, we do not want to update the learned word weights in this model, therefore we will set the trainable attribute for the model to be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=4, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 4, 50)             750       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 951\n",
      "Trainable params: 201\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.callbacks import History\n",
    "\n",
    "history_2 = History()\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=4, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.6000 - accuracy: 0.6667 - val_loss: 1.3902 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5944 - accuracy: 0.6667 - val_loss: 1.3763 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5889 - accuracy: 0.6667 - val_loss: 1.3627 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5835 - accuracy: 0.6667 - val_loss: 1.3496 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5782 - accuracy: 0.6667 - val_loss: 1.3372 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5729 - accuracy: 0.6667 - val_loss: 1.3255 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5678 - accuracy: 0.6667 - val_loss: 1.3143 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5627 - accuracy: 0.7778 - val_loss: 1.3035 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5577 - accuracy: 0.7778 - val_loss: 1.2931 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5528 - accuracy: 0.7778 - val_loss: 1.2831 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5479 - accuracy: 0.7778 - val_loss: 1.2735 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5432 - accuracy: 0.7778 - val_loss: 1.2641 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5384 - accuracy: 0.7778 - val_loss: 1.2551 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5338 - accuracy: 0.7778 - val_loss: 1.2464 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5292 - accuracy: 0.7778 - val_loss: 1.2380 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5247 - accuracy: 0.7778 - val_loss: 1.2299 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5203 - accuracy: 0.8889 - val_loss: 1.2221 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5159 - accuracy: 0.8889 - val_loss: 1.2146 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5116 - accuracy: 0.8889 - val_loss: 1.2074 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5074 - accuracy: 0.8889 - val_loss: 1.2006 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5032 - accuracy: 0.8889 - val_loss: 1.1940 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4990 - accuracy: 0.8889 - val_loss: 1.1878 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4949 - accuracy: 0.8889 - val_loss: 1.1819 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4909 - accuracy: 0.8889 - val_loss: 1.1763 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4869 - accuracy: 0.8889 - val_loss: 1.1709 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4830 - accuracy: 0.8889 - val_loss: 1.1659 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4791 - accuracy: 0.8889 - val_loss: 1.1611 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4752 - accuracy: 0.8889 - val_loss: 1.1566 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4714 - accuracy: 0.8889 - val_loss: 1.1524 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4676 - accuracy: 0.8889 - val_loss: 1.1484 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4639 - accuracy: 0.8889 - val_loss: 1.1446 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4602 - accuracy: 0.8889 - val_loss: 1.1411 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4566 - accuracy: 0.8889 - val_loss: 1.1378 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4530 - accuracy: 0.8889 - val_loss: 1.1347 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4494 - accuracy: 0.8889 - val_loss: 1.1318 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4459 - accuracy: 0.8889 - val_loss: 1.1291 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4424 - accuracy: 0.8889 - val_loss: 1.1265 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4389 - accuracy: 0.8889 - val_loss: 1.1241 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4355 - accuracy: 0.8889 - val_loss: 1.1219 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4321 - accuracy: 0.8889 - val_loss: 1.1198 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4288 - accuracy: 0.8889 - val_loss: 1.1178 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4255 - accuracy: 0.8889 - val_loss: 1.1160 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4222 - accuracy: 0.8889 - val_loss: 1.1143 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4189 - accuracy: 1.0000 - val_loss: 1.1127 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4157 - accuracy: 1.0000 - val_loss: 1.1112 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4126 - accuracy: 1.0000 - val_loss: 1.1098 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4094 - accuracy: 1.0000 - val_loss: 1.1084 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4063 - accuracy: 1.0000 - val_loss: 1.1072 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4033 - accuracy: 1.0000 - val_loss: 1.1060 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4002 - accuracy: 1.0000 - val_loss: 1.1049 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3972 - accuracy: 1.0000 - val_loss: 1.1039 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3942 - accuracy: 1.0000 - val_loss: 1.1030 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3913 - accuracy: 1.0000 - val_loss: 1.1020 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3884 - accuracy: 1.0000 - val_loss: 1.1012 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3855 - accuracy: 1.0000 - val_loss: 1.1004 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3827 - accuracy: 1.0000 - val_loss: 1.0997 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3798 - accuracy: 1.0000 - val_loss: 1.0990 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3771 - accuracy: 1.0000 - val_loss: 1.0983 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3743 - accuracy: 1.0000 - val_loss: 1.0977 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3716 - accuracy: 1.0000 - val_loss: 1.0972 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3689 - accuracy: 1.0000 - val_loss: 1.0967 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3662 - accuracy: 1.0000 - val_loss: 1.0962 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3635 - accuracy: 1.0000 - val_loss: 1.0958 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3609 - accuracy: 1.0000 - val_loss: 1.0954 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3583 - accuracy: 1.0000 - val_loss: 1.0951 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3558 - accuracy: 1.0000 - val_loss: 1.0948 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3532 - accuracy: 1.0000 - val_loss: 1.0946 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3507 - accuracy: 1.0000 - val_loss: 1.0944 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3482 - accuracy: 1.0000 - val_loss: 1.0943 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3458 - accuracy: 1.0000 - val_loss: 1.0943 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3433 - accuracy: 1.0000 - val_loss: 1.0943 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3409 - accuracy: 1.0000 - val_loss: 1.0943 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3385 - accuracy: 1.0000 - val_loss: 1.0944 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3361 - accuracy: 1.0000 - val_loss: 1.0945 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3338 - accuracy: 1.0000 - val_loss: 1.0947 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3315 - accuracy: 1.0000 - val_loss: 1.0950 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3292 - accuracy: 1.0000 - val_loss: 1.0953 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3269 - accuracy: 1.0000 - val_loss: 1.0957 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3247 - accuracy: 1.0000 - val_loss: 1.0961 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3224 - accuracy: 1.0000 - val_loss: 1.0966 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3202 - accuracy: 1.0000 - val_loss: 1.0971 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3180 - accuracy: 1.0000 - val_loss: 1.0977 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3159 - accuracy: 1.0000 - val_loss: 1.0984 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3137 - accuracy: 1.0000 - val_loss: 1.0991 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3116 - accuracy: 1.0000 - val_loss: 1.0998 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3095 - accuracy: 1.0000 - val_loss: 1.1006 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3074 - accuracy: 1.0000 - val_loss: 1.1015 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3053 - accuracy: 1.0000 - val_loss: 1.1024 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3033 - accuracy: 1.0000 - val_loss: 1.1034 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3013 - accuracy: 1.0000 - val_loss: 1.1044 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2993 - accuracy: 1.0000 - val_loss: 1.1054 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2973 - accuracy: 1.0000 - val_loss: 1.1065 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2953 - accuracy: 1.0000 - val_loss: 1.1077 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2934 - accuracy: 1.0000 - val_loss: 1.1089 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2915 - accuracy: 1.0000 - val_loss: 1.1101 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2895 - accuracy: 1.0000 - val_loss: 1.1114 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2876 - accuracy: 1.0000 - val_loss: 1.1127 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2858 - accuracy: 1.0000 - val_loss: 1.1140 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2839 - accuracy: 1.0000 - val_loss: 1.1154 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2821 - accuracy: 1.0000 - val_loss: 1.1169 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7b3f16908>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(padded_docs, labels, epochs=100, validation_split=0.1, callbacks=[history_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.999998\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_1.history['accuracy'], label = \"tarina Trainable\")\n",
    "plt.plot(history_1.history['val_accuracy'], label = \"test Trainable\")\n",
    "\n",
    "plt.plot(history_2.history['accuracy'], label = \"tarina Not Trainable\")\n",
    "plt.plot(history_2.history['val_accuracy'], label = \"test Not Trainable\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
