{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "print(tf.__version__)\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, SimpleRNN, LSTM, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import History\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Embedding layer is defined as the first hidden layer of a network. It must specify 3 arguments:\n",
    "\n",
    "It must specify 3 arguments:\n",
    "\n",
    "* **input_dim**: This is the size of the vocabulary in the text data. For example, if your data is integer encoded to values between 0-10, then the size of the vocabulary would be 11 words.\n",
    "* **output_dim**: This is the size of the vector space in which words will be embedded. It defines the size of the output vectors from this layer for each word. For example, it could be 32 or 100 or even larger. Test different values for your problem.\n",
    "* **input_length**: This is the length of input sequences, as you would define for any input layer of a Keras model. For example, if all of your input documents are comprised of 1000 words, this would be 1000.\n",
    "\n",
    "# Zad. \n",
    "Podążamy za stroną: \n",
    "\n",
    "https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "\n",
    "mamy jakiś zbiór tekstów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "    'Good work',\n",
    "    'Great effort',\n",
    "    'nice work',\n",
    "    'Excellent!',\n",
    "    'Weak',\n",
    "    'Poor effort!',\n",
    "    'not good',\n",
    "    'poor work',\n",
    "    'Could have done better.']\n",
    "# define class labels\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do warstwy **Embedding layer** wchodzi sekwencja intów.\n",
    "\n",
    "* my wykorzystamy reprezenatację Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37, 34], [49, 4], [1, 11], [30, 4], [43], [31], [19, 11], [34, 49], [19, 4], [6, 23, 34, 40]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekwencje mają różne długości, a Keras wymaga aby wejścia były równej długość."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37 34  0  0]\n",
      " [49  4  0  0]\n",
      " [ 1 11  0  0]\n",
      " [30  4  0  0]\n",
      " [43  0  0  0]\n",
      " [31  0  0  0]\n",
      " [19 11  0  0]\n",
      " [34 49  0  0]\n",
      " [19  4  0  0]\n",
      " [ 6 23 34 40]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Embeding ma rakres 50 i długość wejściową 4. Zmniejszmy embending do wymiaru 8.\n",
    "* Model jest prostym klasyfikatorem binarnym. \n",
    "* Co ważne, wynik z warstwy Embeding będzie wynosił 4 wektory o 8 wymiarach każdy, po jednym dla każdego słowa. \n",
    "* Spłaszczamy to do jednego 32-elementowego wektora, aby przejść do warstwy wyjściowej Dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 89.999998\n"
     ]
    }
   ],
   "source": [
    "history_1 = History()\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6368 - accuracy: 0.8889 - val_loss: 0.5692 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6354 - accuracy: 0.8889 - val_loss: 0.5691 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6340 - accuracy: 0.8889 - val_loss: 0.5690 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6325 - accuracy: 0.8889 - val_loss: 0.5690 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6311 - accuracy: 0.8889 - val_loss: 0.5689 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6296 - accuracy: 0.8889 - val_loss: 0.5688 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6282 - accuracy: 0.8889 - val_loss: 0.5688 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6267 - accuracy: 0.8889 - val_loss: 0.5687 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6253 - accuracy: 0.8889 - val_loss: 0.5686 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6238 - accuracy: 0.8889 - val_loss: 0.5685 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6223 - accuracy: 0.8889 - val_loss: 0.5684 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6209 - accuracy: 0.8889 - val_loss: 0.5683 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6194 - accuracy: 0.8889 - val_loss: 0.5682 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6179 - accuracy: 0.8889 - val_loss: 0.5681 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6165 - accuracy: 0.8889 - val_loss: 0.5679 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6150 - accuracy: 0.8889 - val_loss: 0.5678 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6135 - accuracy: 0.8889 - val_loss: 0.5677 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6120 - accuracy: 0.8889 - val_loss: 0.5675 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6105 - accuracy: 0.8889 - val_loss: 0.5674 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6090 - accuracy: 0.8889 - val_loss: 0.5672 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6075 - accuracy: 0.8889 - val_loss: 0.5670 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6060 - accuracy: 0.8889 - val_loss: 0.5669 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6045 - accuracy: 0.8889 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6030 - accuracy: 0.8889 - val_loss: 0.5665 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6015 - accuracy: 0.8889 - val_loss: 0.5663 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6000 - accuracy: 0.8889 - val_loss: 0.5661 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5985 - accuracy: 0.8889 - val_loss: 0.5659 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5969 - accuracy: 0.8889 - val_loss: 0.5656 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5954 - accuracy: 0.8889 - val_loss: 0.5654 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5939 - accuracy: 0.8889 - val_loss: 0.5652 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5923 - accuracy: 0.8889 - val_loss: 0.5649 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5908 - accuracy: 0.8889 - val_loss: 0.5646 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5892 - accuracy: 0.8889 - val_loss: 0.5644 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5877 - accuracy: 0.8889 - val_loss: 0.5641 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5861 - accuracy: 0.8889 - val_loss: 0.5638 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5845 - accuracy: 0.8889 - val_loss: 0.5635 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5830 - accuracy: 0.8889 - val_loss: 0.5631 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5814 - accuracy: 0.8889 - val_loss: 0.5628 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5798 - accuracy: 0.8889 - val_loss: 0.5625 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5782 - accuracy: 0.8889 - val_loss: 0.5621 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5766 - accuracy: 0.8889 - val_loss: 0.5617 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5750 - accuracy: 0.8889 - val_loss: 0.5614 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5734 - accuracy: 0.8889 - val_loss: 0.5610 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5717 - accuracy: 0.8889 - val_loss: 0.5606 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5701 - accuracy: 0.8889 - val_loss: 0.5602 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5685 - accuracy: 0.8889 - val_loss: 0.5598 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5668 - accuracy: 0.8889 - val_loss: 0.5594 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5651 - accuracy: 0.8889 - val_loss: 0.5590 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5635 - accuracy: 0.8889 - val_loss: 0.5586 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5618 - accuracy: 0.8889 - val_loss: 0.5581 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5601 - accuracy: 0.8889 - val_loss: 0.5577 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5584 - accuracy: 0.8889 - val_loss: 0.5573 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5567 - accuracy: 0.8889 - val_loss: 0.5568 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5550 - accuracy: 0.8889 - val_loss: 0.5564 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5533 - accuracy: 0.8889 - val_loss: 0.5559 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5516 - accuracy: 0.8889 - val_loss: 0.5555 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5498 - accuracy: 0.8889 - val_loss: 0.5550 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5481 - accuracy: 0.8889 - val_loss: 0.5546 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5463 - accuracy: 0.8889 - val_loss: 0.5541 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5446 - accuracy: 0.8889 - val_loss: 0.5536 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5428 - accuracy: 0.8889 - val_loss: 0.5532 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5411 - accuracy: 0.8889 - val_loss: 0.5527 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5393 - accuracy: 0.8889 - val_loss: 0.5523 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5375 - accuracy: 0.8889 - val_loss: 0.5518 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5357 - accuracy: 0.8889 - val_loss: 0.5513 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5339 - accuracy: 0.8889 - val_loss: 0.5509 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5321 - accuracy: 0.8889 - val_loss: 0.5504 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5303 - accuracy: 0.8889 - val_loss: 0.5499 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5285 - accuracy: 0.8889 - val_loss: 0.5495 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5266 - accuracy: 0.8889 - val_loss: 0.5490 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5248 - accuracy: 0.8889 - val_loss: 0.5485 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5230 - accuracy: 0.8889 - val_loss: 0.5481 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5211 - accuracy: 0.8889 - val_loss: 0.5476 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5193 - accuracy: 0.8889 - val_loss: 0.5471 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5174 - accuracy: 0.8889 - val_loss: 0.5467 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5156 - accuracy: 0.8889 - val_loss: 0.5462 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5137 - accuracy: 0.8889 - val_loss: 0.5458 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5118 - accuracy: 0.8889 - val_loss: 0.5453 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5099 - accuracy: 0.8889 - val_loss: 0.5448 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5081 - accuracy: 0.8889 - val_loss: 0.5444 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5062 - accuracy: 0.8889 - val_loss: 0.5439 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5043 - accuracy: 0.8889 - val_loss: 0.5434 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5024 - accuracy: 0.8889 - val_loss: 0.5430 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5005 - accuracy: 0.8889 - val_loss: 0.5425 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4986 - accuracy: 0.8889 - val_loss: 0.5421 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4966 - accuracy: 0.8889 - val_loss: 0.5416 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4947 - accuracy: 0.8889 - val_loss: 0.5411 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4928 - accuracy: 0.8889 - val_loss: 0.5407 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4909 - accuracy: 0.8889 - val_loss: 0.5402 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4889 - accuracy: 0.8889 - val_loss: 0.5397 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4870 - accuracy: 0.8889 - val_loss: 0.5393 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4851 - accuracy: 0.8889 - val_loss: 0.5388 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4831 - accuracy: 0.8889 - val_loss: 0.5384 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4812 - accuracy: 0.8889 - val_loss: 0.5379 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4792 - accuracy: 0.8889 - val_loss: 0.5375 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4773 - accuracy: 0.8889 - val_loss: 0.5370 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4753 - accuracy: 0.8889 - val_loss: 0.5366 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4734 - accuracy: 0.8889 - val_loss: 0.5361 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4714 - accuracy: 0.8889 - val_loss: 0.5356 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4694 - accuracy: 1.0000 - val_loss: 0.5352 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x4032f8a08>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# # fit the model\n",
    "# model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(padded_docs, labels, epochs=100, validation_split=0.1, callbacks=[history_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_1.history['accuracy'], label = \"tarina Adam\")\n",
    "plt.plot(history_1.history['val_accuracy'], label = \"test Adam\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain embedding\n",
    "\n",
    "https://keras.io/examples/pretrained_word_embeddings/\n",
    "\n",
    "* GloVe embedding data can be found at: http://nlp.stanford.edu/data/glove.6B.zip (source page: http://nlp.stanford.edu/projects/glove/)\n",
    "\n",
    "* After downloading and unzipping, you will see a few files, one of which is “glove.6B.50d.txt“, which contains a 100-dimensional version of the embedding.\n",
    "\n",
    "\n",
    "Pojedyńczy plik można pobrać z tąd:\n",
    "https://www.dropbox.com/sh/tjq47ybybgnrbel/AAAVbp0UkQTAbKWVMIi5mtHpa?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = ''\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, 'glove.6B.50d')\n",
    "\n",
    "# first, build index mapping words in the embeddings set\n",
    "# to their embedding vector\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "# file = open(filename, encoding=\"utf8\")\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.50d.txt'), encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
    "        embeddings_index[word] = coefs\n",
    "        \n",
    "\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
       "       -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
       "        2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
       "        1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
       "       -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
       "       -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
       "        4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
       "        7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
       "       -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
       "        1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index[\"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better.']\n",
    "# define class labels\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides a Tokenizer class that can be fit on the training data, can convert text to sequences consistently by calling the texts_to_sequences() method on the Tokenizer class, and provides access to the dictionary mapping of words to integers in a word_index attribute.\n",
    "\n",
    "https://keras.io/preprocessing/text/#tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekwencje mają różne długości, a Keras wymaga aby wejścia były równej długość."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  2  0  0]\n",
      " [ 3  1  0  0]\n",
      " [ 7  4  0  0]\n",
      " [ 8  1  0  0]\n",
      " [ 9  0  0  0]\n",
      " [10  0  0  0]\n",
      " [ 5  4  0  0]\n",
      " [11  3  0  0]\n",
      " [ 5  1  0  0]\n",
      " [12 13  2 14]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to create a matrix of one embedding for each word in the training dataset. We can do that by enumerating all unique words in the Tokenizer.word_index and locating the embedding weight vector from the loaded GloVe embedding.\n",
    "\n",
    "The result is a matrix of weights only for words we will see during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 50)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 50))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "embedding_matrix.shape        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.13589978e-01,  1.96950004e-01, -5.19439995e-01, -8.62179995e-01,\n",
       "        1.54940002e-02,  1.09729998e-01, -8.02929997e-01, -3.33609998e-01,\n",
       "       -1.61189993e-04,  1.01889996e-02,  4.67340015e-02,  4.67510015e-01,\n",
       "       -4.74750012e-01,  1.10380001e-01,  3.93269986e-01, -4.36520010e-01,\n",
       "        3.99839997e-01,  2.71090001e-01,  4.26499993e-01, -6.06400013e-01,\n",
       "        8.11450005e-01,  4.56299990e-01, -1.27260000e-01, -2.24739999e-01,\n",
       "        6.40709996e-01, -1.27670002e+00, -7.22310007e-01, -6.95900023e-01,\n",
       "        2.80450005e-02, -2.30719998e-01,  3.79959989e+00, -1.26249999e-01,\n",
       "       -4.79669988e-01, -9.99719977e-01, -2.19760001e-01,  5.05649984e-01,\n",
       "        2.59530004e-02,  8.05140018e-01,  1.99290007e-01,  2.87959993e-01,\n",
       "       -1.59150004e-01, -3.04380000e-01,  1.60249993e-01, -1.82899997e-01,\n",
       "       -3.85629982e-02, -1.76190004e-01,  2.70409994e-02,  4.68420014e-02,\n",
       "       -6.28970027e-01,  3.57259989e-01])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 20 is out of bounds for axis 0 with size 15",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-2cda3954143e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0membedding_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 20 is out of bounds for axis 0 with size 15"
     ]
    }
   ],
   "source": [
    "embedding_matrix[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key difference is that the embedding layer can be seeded with the GloVe word embedding weights. We chose the 50-dimensional version, therefore the Embedding layer must be defined with output_dim set to 50. Finally, we do not want to update the learned word weights in this model, therefore we will set the trainable attribute for the model to be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=4, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4, 50)             750       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 951\n",
      "Trainable params: 201\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.callbacks import History\n",
    "\n",
    "history_2 = History()\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=4, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.6536 - accuracy: 0.6667 - val_loss: 0.6921 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6483 - accuracy: 0.6667 - val_loss: 0.6871 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6430 - accuracy: 0.6667 - val_loss: 0.6819 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6379 - accuracy: 0.6667 - val_loss: 0.6766 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6328 - accuracy: 0.6667 - val_loss: 0.6714 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6277 - accuracy: 0.7778 - val_loss: 0.6663 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6228 - accuracy: 0.7778 - val_loss: 0.6613 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6179 - accuracy: 0.7778 - val_loss: 0.6564 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6130 - accuracy: 0.7778 - val_loss: 0.6517 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6082 - accuracy: 0.7778 - val_loss: 0.6471 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6035 - accuracy: 0.7778 - val_loss: 0.6427 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5989 - accuracy: 0.7778 - val_loss: 0.6384 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5943 - accuracy: 0.7778 - val_loss: 0.6342 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5897 - accuracy: 0.7778 - val_loss: 0.6302 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5852 - accuracy: 0.7778 - val_loss: 0.6263 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5808 - accuracy: 0.7778 - val_loss: 0.6226 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5764 - accuracy: 0.7778 - val_loss: 0.6190 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5721 - accuracy: 0.7778 - val_loss: 0.6157 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5678 - accuracy: 0.7778 - val_loss: 0.6125 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5636 - accuracy: 0.7778 - val_loss: 0.6094 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5594 - accuracy: 0.7778 - val_loss: 0.6066 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5552 - accuracy: 0.7778 - val_loss: 0.6040 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5511 - accuracy: 0.7778 - val_loss: 0.6015 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5471 - accuracy: 0.7778 - val_loss: 0.5992 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5431 - accuracy: 0.7778 - val_loss: 0.5972 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5391 - accuracy: 0.7778 - val_loss: 0.5953 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5351 - accuracy: 0.7778 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5312 - accuracy: 0.7778 - val_loss: 0.5920 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5273 - accuracy: 0.7778 - val_loss: 0.5906 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5235 - accuracy: 0.7778 - val_loss: 0.5894 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5197 - accuracy: 0.7778 - val_loss: 0.5883 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5159 - accuracy: 0.7778 - val_loss: 0.5874 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5122 - accuracy: 0.7778 - val_loss: 0.5866 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5085 - accuracy: 0.7778 - val_loss: 0.5860 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5048 - accuracy: 0.8889 - val_loss: 0.5855 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5012 - accuracy: 0.8889 - val_loss: 0.5851 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4976 - accuracy: 0.8889 - val_loss: 0.5848 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4940 - accuracy: 0.8889 - val_loss: 0.5846 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4905 - accuracy: 0.8889 - val_loss: 0.5845 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4870 - accuracy: 0.8889 - val_loss: 0.5846 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4835 - accuracy: 0.8889 - val_loss: 0.5846 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4801 - accuracy: 0.8889 - val_loss: 0.5848 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4767 - accuracy: 1.0000 - val_loss: 0.5850 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4733 - accuracy: 1.0000 - val_loss: 0.5853 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4700 - accuracy: 1.0000 - val_loss: 0.5857 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4667 - accuracy: 1.0000 - val_loss: 0.5861 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4634 - accuracy: 1.0000 - val_loss: 0.5865 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4602 - accuracy: 1.0000 - val_loss: 0.5870 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4570 - accuracy: 1.0000 - val_loss: 0.5875 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4538 - accuracy: 1.0000 - val_loss: 0.5880 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4506 - accuracy: 1.0000 - val_loss: 0.5886 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4475 - accuracy: 1.0000 - val_loss: 0.5892 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4444 - accuracy: 1.0000 - val_loss: 0.5898 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4413 - accuracy: 1.0000 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4383 - accuracy: 1.0000 - val_loss: 0.5911 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4353 - accuracy: 1.0000 - val_loss: 0.5918 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4323 - accuracy: 1.0000 - val_loss: 0.5925 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4293 - accuracy: 1.0000 - val_loss: 0.5933 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4264 - accuracy: 1.0000 - val_loss: 0.5940 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4235 - accuracy: 1.0000 - val_loss: 0.5948 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4206 - accuracy: 1.0000 - val_loss: 0.5956 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4178 - accuracy: 1.0000 - val_loss: 0.5964 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4149 - accuracy: 1.0000 - val_loss: 0.5972 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4121 - accuracy: 1.0000 - val_loss: 0.5981 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4094 - accuracy: 1.0000 - val_loss: 0.5990 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4066 - accuracy: 1.0000 - val_loss: 0.6000 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4039 - accuracy: 1.0000 - val_loss: 0.6009 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4012 - accuracy: 1.0000 - val_loss: 0.6019 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3985 - accuracy: 1.0000 - val_loss: 0.6029 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3958 - accuracy: 1.0000 - val_loss: 0.6040 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3932 - accuracy: 1.0000 - val_loss: 0.6051 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3906 - accuracy: 1.0000 - val_loss: 0.6062 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3880 - accuracy: 1.0000 - val_loss: 0.6074 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3855 - accuracy: 1.0000 - val_loss: 0.6086 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3829 - accuracy: 1.0000 - val_loss: 0.6098 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3804 - accuracy: 1.0000 - val_loss: 0.6111 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3779 - accuracy: 1.0000 - val_loss: 0.6124 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3754 - accuracy: 1.0000 - val_loss: 0.6138 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3730 - accuracy: 1.0000 - val_loss: 0.6152 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3705 - accuracy: 1.0000 - val_loss: 0.6166 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3681 - accuracy: 1.0000 - val_loss: 0.6180 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3657 - accuracy: 1.0000 - val_loss: 0.6195 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3634 - accuracy: 1.0000 - val_loss: 0.6210 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3610 - accuracy: 1.0000 - val_loss: 0.6226 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3587 - accuracy: 1.0000 - val_loss: 0.6242 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3564 - accuracy: 1.0000 - val_loss: 0.6258 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3541 - accuracy: 1.0000 - val_loss: 0.6274 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3518 - accuracy: 1.0000 - val_loss: 0.6291 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3496 - accuracy: 1.0000 - val_loss: 0.6308 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3473 - accuracy: 1.0000 - val_loss: 0.6325 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3451 - accuracy: 1.0000 - val_loss: 0.6342 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3429 - accuracy: 1.0000 - val_loss: 0.6360 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3408 - accuracy: 1.0000 - val_loss: 0.6377 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3386 - accuracy: 1.0000 - val_loss: 0.6395 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3365 - accuracy: 1.0000 - val_loss: 0.6413 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3343 - accuracy: 1.0000 - val_loss: 0.6431 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3322 - accuracy: 1.0000 - val_loss: 0.6450 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3301 - accuracy: 1.0000 - val_loss: 0.6468 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3281 - accuracy: 1.0000 - val_loss: 0.6487 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3260 - accuracy: 1.0000 - val_loss: 0.6506 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x40f9d1908>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(padded_docs, labels, epochs=100, validation_split=0.1, callbacks=[history_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXhU5d3/8fc3JBBAFEpQkbCpKFAokeYCZKlgWQylApZLRSnYp/5ww6VVCyiK4oYPz+Nj+xPtQ0FwoVB+WJa2iIBgKWUNEJBFVhFDrASUFJhAMuH+/TGTONknJJPJTD6v68rFnPsscx8OfOeb+5z53uacQ0REoldMuDsgIiKhpUAvIhLlFOhFRKKcAr2ISJRToBcRiXKx4e5AUQkJCa5Nmzbh7oaISETZunXrCedcs5LW1bhA36ZNG1JTU8PdDRGRiGJmX5S2TkM3IiJRToFeRCTKKdCLiEQ5BXoRkSinQC8iEuXKDfRm9raZHTezXaWsNzP7nZkdNLOdZtY1YN0YMzvg/xlTlR0XEZHgBJPRzwFuKWN9CtDO/zMWeAvAzL4HTAa6A92AyWbWpDKdFRGRiiv3OXrn3Foza1PGJkOBd52v3vFGM2tsZs2BvsBK59w3AGa2Et8HxrzKdro0/xr7E85/nhGqw0sE+IY8slHpbYk8ec7hufJSBr2/vsqPXRVfmGoBfBmwnO5vK629GDMbi++3AVq1alUFXZLa6nO8XDCHYr1EHIOTF86G5NBVEeithDZXRnvxRudmADMAkpOTL/q/6JUz/naxu0oUyM3LZcj7XXn4hocZ+4Ox4e6OSIUMm/5PGsXHcl8Ijl0VT92kAy0DlhOBjDLaRULC4/UAUD+2fph7IlJxnhwvDeuGpipNVQT6pcBo/9M3PYAs59xXwEfAQDNr4r8JO9DfJhIS2d5sABrENghzT0Qq7uz5PBrUqxOSY5f78WFm8/DdWE0ws3R8T9LEATjnfg8sAwYDBwEP8Av/um/M7AVgi/9QU/JvzIqEgifXl9E3iFOgl8gTyow+mKduRpaz3gEPlbLubeDti+uaSMXkD90oo5dIdDYndBm9vhkrUUMZvUSq3LwL5Hgv1OgxepEaQRm9RCpPTh4ADeoqoxcpU35GXz9OT91IZMn2B/qG9ZTRi5RJGb1EqrM5XkAZvUi5NEYvkcpzPn/oRhm9SJn0hSmJVPkZfUNl9CJly/ZmUzemLnExceHuikiFePKHbjRGL1I2T65HwzYSkc76h26U0YuUw+P16EasRCRl9CJByvZmK6OXiKSMXiRInlxl9BKZCjJ6PXUjUjaP16MvS0lEOpuTR1wdo25saEKyAr1EDU+uR49WSkTynPeGLJsHBXqJIroZK5HqbE5eyMbnQYFeooger5RI5cnxhuyJG1CglyiijF4i1dnzyuhFynXBXdDjlRKxPDkaoxcp1znvOUCVKyUynT2fR8MQzS4FCvQSJVSiWCJZdm6eMnqR8qhEsUSys+e9yuhFyqOMXiKZJ6cGZPRmdouZ7TOzg2Y2oYT1rc3sYzPbaWafmFliwLo8M0vz/yytys6L5NM0ghKpnHOczfGG9Kmbcj9CzKwOMB0YAKQDW8xsqXNuT8Bm/wW865x7x8xuBl4Bfu5fl+2cS6rifosUooxeItW53As4F7rKlRBcRt8NOOicO+ycywHmA0OLbNMR+Nj/ek0J60VCSmP0EqlCPV8sBBfoWwBfBiyn+9sC7QB+5n89HGhkZk39y/FmlmpmG81sWElvYGZj/dukZmZmVqD7Ij7K6CVShXq+WAgu0FsJba7I8hPATWa2HbgJOAZ4/etaOeeSgbuA183smmIHc26Gcy7ZOZfcrFmz4Hsv4qeMXiJVqOeLhSDG6PFl8C0DlhOBjMANnHMZwG0AZnYJ8DPnXFbAOpxzh83sE+AG4FCley4SINubDSijl8gT6tmlILiMfgvQzszamlld4E6g0NMzZpZgZvnHmgi87W9vYmb18rcBegGBN3FFqoTH6yHGYqhXp164uyJSIaGeXQqCCPTOOS8wDvgI2AsscM7tNrMpZnarf7O+wD4z2w9cAbzkb+8ApJrZDnw3aacWeVpHpErk16I3K2mkUaTmCvXsUhDc0A3OuWXAsiJtzwa8XggsLGG/9UDnSvZRpFzZ3mwN20hEKsjo9c1YkbKpFr1EqurI6BXoJSqoFr1EqrM5yuhFguLxar5YiUye817MID5WgV6kTBq6kUh1NiePBnF1iIkJ3YMECvQSFTR0I5HKk5MX0mfoQYFeooQyeolUnhBXrgQFeokSyuglUp09H9pa9KBAL1HAOUd2riYGl8jkyQnt7FKgQC9RIPdCLl7nVUYvEelsiGeXAgV6iQKqXCmRzBPi+WJBgV6igGrRSyQL9XyxoEAvUUDzxUokO5vjDensUqBAL1FAGb1EMo+euhEpnwK9RKoc7wVy8i7oOXqR8mjoRiJVtr+gmb4ZK1IOZfQSqapjvlhQoJcoUPB4pQK9RJjqmC8WFOglChRMDK7n6CXCVMd8saBAL1Egf+hG9egl0pythtmlQIFeokB2bjb16tQjNia0/1lEqpqnGuaLhSADvZndYmb7zOygmU0oYX1rM/vYzHaa2SdmlhiwboyZHfD/jKnKzouAKldK5PLk+p+6CXdGb2Z1gOlACtARGGlmHYts9l/Au865HwBTgFf8+34PmAx0B7oBk82sSdV1X0S16CVyec77n7qpARl9N+Cgc+6wcy4HmA8MLbJNR+Bj/+s1AesHASudc984574FVgK3VL7bIt/RfLESqfInBg97Rg+0AL4MWE73twXaAfzM/3o40MjMmga5r0ilKKOXSJWf0deEWjclzVjriiw/AdxkZtuBm4BjgDfIfTGzsWaWamapmZmZQXRJ5Dsao5dIdTYnj7qxMcTVCe1zMcEcPR1oGbCcCGQEbuCcy3DO3eacuwF42t+WFcy+/m1nOOeSnXPJzZo1q+ApSG2nQC+Rqjrmi4XgAv0WoJ2ZtTWzusCdwNLADcwswczyjzUReNv/+iNgoJk18d+EHehvE6kyGrqRSFUd88VCEIHeOecFxuEL0HuBBc653WY2xcxu9W/WF9hnZvuBK4CX/Pt+A7yA78NiCzDF3yZSZbK92croJSJVx3yxAEF9lDjnlgHLirQ9G/B6IbCwlH3f5rsMX6TKKaOXSFUd88VCkIE+Epw57+X5pbvD3Q0pw78vHOGL3JWUcD++Us7lneMf+7L41+c7qvS4IqG2J+PfXHfFJSF/n6gJ9LneC/zz4Ilwd0PKcO7Sj8htuA7Lu6xKj2s0JePklRw/r+svkaVuHaNPu9A/gBI1gb5Jw7qsn/jjcHdDyvDMPz9h41dXsHLEynB3RaRWUVEzqTaeXD0GKRIOCvRSbfS8u0h4KNBLtdHTMSLhoUAv1UbPu4uEhwK9VBuP10P9OFWZFKluCvRSbXQzViQ8FOil2ni8GqMXCQcFeqkWzjk8uZogRCQcFOilWpzLO4fDaehGJAwU6KVaeHI9ABq6EQkDBXqpFh6vP9Aroxepdgr0Ui2U0YuEjwK9VItsbzagjF4kHBTopVoooxcJHwV6qRYaoxcJHwV6qRYK9CLho0Av1SI71zdGr1o3ItVPgV6qhTJ6kfAJKtCb2S1mts/MDprZhBLWtzKzNWa23cx2mtlgf3sbM8s2szT/z++r+gQkMni8HgwjPjY+3F0RqXXKnTPWzOoA04EBQDqwxcyWOuf2BGw2CVjgnHvLzDoCy4A2/nWHnHNJVdttiTT5dW5iTL9EilS3YP7XdQMOOucOO+dygPnA0CLbOOBS/+vLgIyq66JEA1WuFAmfYAJ9C+DLgOV0f1ug54BRZpaOL5t/OGBdW/+Qzt/NrE9Jb2BmY80s1cxSMzMzg++9RAzVohcJn2ACvZXQ5oosjwTmOOcSgcHAe2YWA3wFtHLO3QD8GvijmV1aZF+cczOcc8nOueRmzZpV7AwkIiijFwmfYAJ9OtAyYDmR4kMzvwQWADjnNgDxQIJz7rxz7qS/fStwCLiusp2WyJOdq/liRcIlmEC/BWhnZm3NrC5wJ7C0yDZHgR8DmFkHfIE+08ya+W/mYmZXA+2Aw1XVeYkcmi9WJHzKDfTOOS8wDvgI2Ivv6ZrdZjbFzG71b/Y48H/MbAcwD7jHOeeAHwE7/e0Lgfudc9+E4kSkZtMYvUj4lPt4JYBzbhm+m6yBbc8GvN4D9Cphvw+ADyrZR4kCHq8CvUi46KFmqRa6GSsSPgr0Ui00MbhI+CjQS8jl5uWSeyFXQzciYaJALyFXUNBMQzciYaFALyGnaQRFwkuBXkJO0wiKhJcCvYScatGLhJcCvYScMnqR8FKgl5BTRi8SXgr0EnL5N2NV60YkPBToJeQKhm6U0YuEhQK9hJyeoxcJLwV6Cbn8jF4lEETCQ4FeQs7j9VA3pi5xMXHh7opIraRALyHnyVXlSpFwUqCXkFMtepHwUqCXkMv2ZiujFwkjBXoJOU0jKBJeCvQScpoYXCS8FOgl5JTRi4SXAr2EnOaLFQmvoAK9md1iZvvM7KCZTShhfSszW2Nm281sp5kNDlg30b/fPjMbVJWdl8igjF4kvGLL28DM6gDTgQFAOrDFzJY65/YEbDYJWOCce8vMOgLLgDb+13cC3weuAlaZ2XXOubyqPhGpuTxeTQwuEk7BZPTdgIPOucPOuRxgPjC0yDYOuNT/+jIgw/96KDDfOXfeOfc5cNB/PKklLrgLerxSJMyCCfQtgC8DltP9bYGeA0aZWTq+bP7hCuyLmY01s1QzS83MzAyy6xIJznnPAapcKRJOwQR6K6HNFVkeCcxxziUCg4H3zCwmyH1xzs1wziU755KbNWsWRJckUmjSEZHwK3eMHl8W3jJgOZHvhmby/RK4BcA5t8HM4oGEIPeVKKZpBEXCL5iMfgvQzszamlldfDdXlxbZ5ijwYwAz6wDEA5n+7e40s3pm1hZoB2yuqs5LzaeMXiT8ys3onXNeMxsHfATUAd52zu02sylAqnNuKfA48Acz+xW+oZl7nHMO2G1mC4A9gBd4SE/c1C4Ftej1zViRsAlm6Abn3DJ8N1kD254NeL0H6FXKvi8BL1WijxLBlNGLhJ++GSshlT8xuMboRcJHgV5CShODi4SfAr2ElCYGFwk/BXoJKWX0IuGnQC8h5fF6iLEY6tWpF+6uiNRaCvQSUvmVK81K+pK0iFSHoB6vrA3+eviv/OXQX8Ldjahz6NQhDduIhJkCvd/iA4vZdXIX1zS+JtxdiSpXNLyC7ld2D3c3RGo1BXo/j9dDl2Zd+N8B/xvuroiIVCmN0ftle7M1xCAiUUmB3s+Tq3lNRSQ6KdD7abo7EYlWCvR+yuhFJFop0AO5F3LJuZCjMXoRiUoK9ARUWFSgF5EopMcr0XR3UvPk5uaSnp7OuXPnwt0VqWHi4+NJTEwkLi4u6H0U6NHkGFLzpKen06hRI9q0aaPyEVLAOcfJkydJT0+nbdu2Qe+noRsgO1eTY0jNcu7cOZo2baogL4WYGU2bNq3wb3oK9Cijl5pJQV5KcjH/LhTo0Ri9iES3oAK9md1iZvvM7KCZTShh/f+YWZr/Z7+ZnQpYlxewbmlVdr6qKKMXKezUqVO8+eabF7Xv4MGDOXXqVPkblmH27NkkJSWRlJRE3bp16dy5M0lJSUyYUCz8lOrLL7/kjjvuuOg+JCYmlngekyZN4vXXX7/o44ZDuTdjzawOMB0YAKQDW8xsqXNuT/42zrlfBWz/MHBDwCGynXNJVdflqpef0eubsSI++YH+wQcfDHof5xzOOZYtW1bp9//FL37BL37xCwDatGnDmjVrSEhIKLad1+slNrbkMNayZUv+9Kc/Vbov0SCYp266AQedc4cBzGw+MBTYU8r2I4HJVdO96qF5TaUme/4vu9mT8e8qPWbHqy5l8k+/X+r6CRMmcOjQIZKSkhgwYACTJ09m6NChfPvtt+Tm5vLiiy8ydOhQjhw5QkpKCv369WPDhg0sXryYm266idTUVM6cOUNKSgq9e/dm/fr1tGjRgiVLllC/fn3+8Ic/MGPGDHJycrj22mt57733aNAguP9/kyZNIjMzk8OHD3PllVfy3HPPcc8993DmzBliYmJ488036d69OwcPHmTEiBGkpaUxc+ZMli9fzunTpzl8+DAjRozglVdeAWDs2LFs27aN7Oxs7rjjDp599tmC95o6dSqrV6/GzJg3bx5XX311ob4cOHCAcePGceLECRo2bMjMmTO57rrrLuKKhFYwQzctgC8DltP9bcWYWWugLbA6oDnezFLNbKOZDStlv7H+bVIzMzOD7HrV0bymIoVNnTqVa665hrS0NKZNm0Z8fDyLFi1i27ZtrFmzhscffxznHAD79u1j9OjRbN++ndatWxc6zoEDB3jooYfYvXs3jRs35oMPPgDgtttuY8uWLezYsYMOHTowa9asCvVv+/bt/OUvf+G9996jefPmrFy5ku3btzN37lweeeSREvfZsWMHCxcuZOfOnbz//vtkZGQUnGtqaio7duxg5cqV7NnzXQ7bpEkTNm/ezH333cevf/3rYsccO3Ysb775Jlu3buWVV15h3LhxFTqP6hJMRl/SLV5XyrZ3Agudc3kBba2ccxlmdjWw2sw+dc4dKnQw52YAMwCSk5NLO3bIeLweYmNiiasT/BcQRKpLWZl3dXHO8dRTT7F27VpiYmI4duwYX3/9NQCtW7emR48eJe7Xtm1bkpJ8I7c//OEPOXLkCAC7du1i0qRJnDp1ijNnzjBo0KAK9Wfo0KHEx8cDcP78ecaNG8eOHTuIjY3l0KFDJe7Tv39/GjVqBED79u05evQoV111FfPmzWPWrFl4vV4yMjLYs2cPHTt2BGDkyJEA3H333cXuD5w6dYqNGzfys5/9rKDN6/VW6DyqSzCBPh1oGbCcCGSUsu2dwEOBDc65DP+fh83sE3zj9yVfiTBRLXqRss2dO5fMzEy2bt1KXFwcbdq0KXiWu2HDhqXuV6/ed5PC16lTh+xs33dW7rnnHhYvXkyXLl2YM2cOn3zySYX6E/ie//3f/03Lli15//33yc3N5ZJLLgmqL16vlwMHDvDb3/6WzZs307hxY0aNGlXoGfWyHmV0zpGQkEBaWlqF+h4OwQzdbAHamVlbM6uLL5gXe3rGzK4HmgAbAtqamFk9/+sEoBelj+2HjSpXihTWqFEjTp8+XbCclZXF5ZdfTlxcHGvWrOGLL76o1PFPnz5N8+bNyc3NZe7cuZU6VlZWFs2bN8fMeOeddwqGlILx73//m0aNGnHppZfy1Vdf8dFHHxVan38zd968efTq1avQuiZNmtC8eXMWLVoEwIULF9ixY0elziVUys3onXNeMxsHfATUAd52zu02sylAqnMuP+iPBOa7wn/LHYD/NbML+D5UpgY+rVNTeLweZfQiAZo2bUqvXr3o1KkTKSkpjB8/np/+9KckJyeTlJRE+/btK3X8F154ge7du9O6dWs6d+5c6EOlosaNG8eIESOYN28e/fv3L5S5l6dr16507NiRTp06cfXVVxcL5h6Ph27duhXcjC1q/vz5PPDAAzz33HPk5OQwatQounTpctHnEipWkU+/6pCcnOxSU1Or9T3vX3U/WeeymDek+IUUCYe9e/fSoUOHcHdDaqiS/n2Y2VbnXHJJ2+ubsfhq3WjoRkSilQI9GroRkeimQI/vZmz9OH0rVkSikwI9yuhFJLop0KPHK0UkutX6QH/BXdAXpkQkqtX6QH/Oew6HU0YvEqAyZYoBXn/9dTweT7H24cOHk5SUxLXXXstll11WUIp4/fr1QR97+vTpF/0lq1WrVjFsWIklt0otSxwNan2gVy16keJCFegXLVpUUE2yT58+pKWlkZaWRs+ePQttV1bNmIceeoi77777ovtWG9X6ycE1X6zUeB9OgH99WrXHvLIzpEwtdXXRMsXTpk1j2rRpLFiwgPPnzzN8+HCef/55zp49y+233056ejp5eXk888wzfP3112RkZNCvXz8SEhJYs2ZNUF1KTEzkvvvuY/ny5Tz22GOcPHmSWbNmkZOTw3XXXce7775L/fr1mTRpEgkJCTz22GP07t2b3r17s3r1arKyspg9ezY9e/bk0KFDJZYuBl/JhGHDhrF//3769evHG2+8UaymzTvvvMP06dPJycmhZ8+evPHGG8TERG5eXOsDvTJ6keKmTp3Krl27Cgp2rVixggMHDrB582acc9x6662sXbuWzMxMrrrqKv72t78BviB62WWX8dprr5U6WUhZGjZsyD//+U8ATp48yf333w/4PnjmzJnDAw88UGwf5xybN29m6dKlTJkyheXLlxeULo6Pj+ezzz5jzJgxbNq0CYBNmzaxZ88eWrZsyYABA1iyZEmh4Zxdu3axaNEi1q9fT2xsLGPHjmX+/PncddddFf+LrCEU6BXopaYrI/OuLitWrGDFihXccINv8rgzZ85w4MAB+vTpwxNPPMH48eMZMmQIffr0qdT7BE79t3PnTp599llOnTrF6dOnGTJkSIn73HbbbUDhMshllS7u0aMHbdq0AeDOO+9k3bp1hQL9qlWr2LJlC8nJvmoC2dnZtGwZWMA38ijQa2JwkXI555g4cSL33XdfsXVbt25l2bJlTJw4kYEDBxaaoamiAssPjx49mg8//JBOnToxc+ZMNm7cWOI++UXM8ksPQ9mli4sO0xRdds7xH//xH7zwwgsXfR41TeQOOlWRbK9vjF7zxYp8p2iZ4kGDBvH2229z5swZAI4dO8bx48fJyMigQYMGjBo1iieeeIJt27aVuP/FOHv2LFdeeSW5ubn88Y9/rNC+ZZUu3rhxI0ePHiUvL48FCxbQu3fvQvv279+fBQsWcOLECcA3hHT06NFKnUu4KaPX0I1IMUXLFE+bNo29e/dy4403AnDJJZfw/vvvc/DgQZ588kliYmKIi4vjrbfeAnxT7KWkpNC8efOgb8YWNWXKFLp160arVq3o1KlToQlBylNW6eKePXvy+OOPs3v3bvr27cutt95aaN/OnTszefJk+vfvz4ULF4iLi+P3v/89rVq1uqjzqAlqfZni+Z/N56VNL7Hm9jUk1K/YjSORUFGZYimLyhRXkDJ6EYl2CvS5HgwjPjY+3F0REQkJBXqvh/qx9YmxWv9XISJRqtZHN1WuFJFop0CvWvQiEuVqfaDXfLEiEu2CCvRmdouZ7TOzg2Y2oYT1/2Nmaf6f/WZ2KmDdGDM74P8ZU5WdrwrK6EWKq0z1ysGDB1dJud85c+YQExPDzp07C9o6depUUOagNC+//HKJ7d27dycpKYlWrVrRrFmzghLJ5R0v0NNPP33R3wuYOXMmjz32WLF2r9dL48aNL+qYwSo30JtZHWA6kAJ0BEaaWcfAbZxzv3LOJTnnkoD/C/zZv+/3gMlAd6AbMNnMmlTtKVSO5osVKe5iAr1zjgsXLrBs2bIqC1yJiYm89NJLFdqntEC/adMm0tLSmDJlCnfccUdBieT8ujf58vLySj32Sy+9RL9+/SrUn5ogmG/GdgMOOucOA5jZfGAosKeU7UfiC+4Ag4CVzrlv/PuuBG4B5lWm01XJ4/XQPLZ5uLshUqpXN7/KZ998VqXHbP+99ozvNr7U9UXLFE+ePJmhQ4fy7bffkpuby4svvsjQoUM5cuQIKSkp9OvXjw0bNrB48WJuuukmUlNTOXPmDCkpKfTu3Zv169fTokULlixZQv369fnDH/7AjBkzyMnJ4dprr+W9996jQYPiv1kPGTKEtWvXsm/fPq6//vpC6+bNm8fLL7+Mc46f/OQnvPrqq0yYMIHs7GySkpL4/ve/H9QEJV6vl4SEBMaNG8eKFSv47W9/y/Lly1m2bBnZ2dn07t2bt956CzNj1KhRjBgxgmHDhpGYmMi9997LkiVLyMvLY+HChVx33XVs3LiRX/3qV5w7d44GDRowZ84c2rVrB8AXX3zBoEGDOHLkCD//+c+ZNGlSsf5MnTqVP//5z5w7d44RI0ZUqnZQvmCGbloAXwYsp/vbijGz1kBbYHVF9jWzsWaWamapmZmZwfS7ymjoRqS4qVOncs0115CWlsa0adOIj49n0aJFbNu2jTVr1vD4448X1I/Zt28fo0ePZvv27bRu3brQcQ4cOMBDDz3E7t27ady4MR988AHgqzi5ZcsWduzYQYcOHZg1a1aJ/YiJieE3v/lNsSw9IyOD8ePHs3r1atLS0tiyZQuLFy9m6tSp1K9fn7S0tArNQpWVlUXXrl3ZvHkzN954I48++ihbtmzh008/JSsri+XLl5e43xVXXMH27du59957ee211wDo0KED69atY/v27TzzzDOFgvnmzZuZP38+27Zt449//GNBGeh8y5Yt4+jRowW/faxfv75Cs2+VJpiM3kpoK61uwp3AQudc/u8+Qe3rnJsBzABfCYQg+lRl9Hil1HRlZd7VxTnHU089xdq1a4mJieHYsWN8/fXXALRu3ZoePXqUuF/btm1JSkoCCpcR3rVrF5MmTeLUqVOcOXOGQYMGlfred911Fy+99BKff/55QduWLVvo27cvzZo1A+Duu+9m7dq1pU4TWJ66desyfPjwguWPP/6YadOmce7cOU6cOMEPf/hDUlJSiu0XWCJ52bJlgG/Ya/To0YVKI+cbNGgQTZr4Rq+HDRvGunXr6NSpU8H6FStW8OGHHxYqB71///5iM3BVVDCBPh0ILMacCGSUsu2dwENF9u1bZN9Pgu9e6CmjFynf3LlzyczMZOvWrcTFxdGmTZuCImOBpYWLCiwmVqdOHbKzfdVi77nnHhYvXkyXLl2YM2cOn3zySanHiI2N5fHHH+fVV18taKvqGl3169cvKFfs8XgYN24c27Zto0WLFkyaNKnUgmollUh++umnGTRoEA8++CAHDx7klltuKdg+mBLJkyZN4pe//GWVnRsEN3SzBWhnZm3NrC6+YL606EZmdj3QBNgQ0PwRMNDMmvhvwg70t9UIuXm5eC94ldGLFFG0zHBWVhaXX345cXFxrFmzhi+++KJSxz99+jTNmzcnNzc3qCGWe+65h1WrVpE/tNu9e3f+/ve/c+LECfLy8pg3bx433XQTAHFxcUWblMcAAAsSSURBVOTm5l5037Kzs4mJiSEhIYHTp08XDDcFKysrixYtfCPUc+bMKbRuxYoVnDp1Co/Hw5IlS+jVq1eh9YMGDWLWrFmcPXsWgPT09IJyyZVRbqB3znmBcfgC9F5ggXNut5lNMbPA+p4jgfku4KPWfxP2BXwfFluAKfk3ZmsCFTQTKVlgmeInn3ySu+++m9TUVJKTk5k7dy7t27ev1PFfeOEFunfvzoABA4I6Vt26dXnkkUc4fvw4AM2bN+eVV16hX79+dOnSha5duzJ06FDAVyL5Bz/4wUVPIN60aVPGjBlDp06dGD58eMFcs8EaP348Tz75ZLEgDtC7d2/uuusubrjhBkaOHFkwrJVv8ODBjBgxgh49etC5c2duv/32gjkAKqNWlyn+19l/MWDhAJ7v+Ty3tbutWt5TJBgqUyxlUZniCiiYRlAZvYhEsdod6L2aL1ZEol/tDvT+jF7zxYpINKvdgV4ZvYjUArU70CujF5FaoHYHej1eKSK1QO0O9LkauhEpSWXKFAO8/vrreDyeEtf17duX5OTvngJMTU2lb9++ZR4vLS2toMRAoI8++qig3PAll1zC9ddfT1JSEqNHjw66r3l5efTp0yfo7Yvq3bt3sZo1UHpZ4nCo3YHeq6EbkZKEMtADHD9+nA8//DDo45UW6AcNGlRQbjj/y1xpaWm8++67hbbLL09Qkjp16vCPf/wj6L5EomBq3UQtj9dD3Zi6xMXEhbsrIqX618svc35v1ZYprtehPVc+9VSp64uWKZ42bRrTpk1jwYIFnD9/nuHDh/P8889z9uxZbr/9dtLT08nLy+OZZ57h66+/JiMjg379+pGQkFDiRB1PPvkkL774YrFCYefOneOBBx4gNTWV2NhYXnvtNXr16sWzzz5LdnY269atY+LEidxxxx3lnuPMmTNZtWoVZ86c4fz583zwwQcMGzaMU6dO4fV6efnllxkyZEhBmeJTp06xatUqXnnlFS677DJ2795N9+7dCz40Jk+eXGLpYvCVOti0aRNnzpxh9uzZhX5jAfj666954IEHOHr0KDExMfzud78rtRBcKNTuQK/KlSIlmjp1Krt27SoYklixYgUHDhxg8+bNOOe49dZbWbt2LZmZmVx11VX87W9/A3x1Xi677DJee+011qxZQ0JCQonHv/HGG1m0aBFr1qyhUaNGBe3Tp08H4NNPP+Wzzz5j4MCB7N+/nylTppCamsobb7xRofPYsGEDaWlpNGnShNzcXJYsWUKjRo04fvw4vXr1YsiQIcX22bZtG3v27OHyyy+nR48ebNy4kR49evDoo4/y/PPP45zjrrvuYvny5QUfVOfPn2fDhg2sXr2ae++9t9hQziOPPMJvfvMbevTowZEjRxgyZAi7du2q0LlURq0O9NnebN2IlRqvrMy7uqxYsYIVK1YUKp974MAB+vTpwxNPPMH48eMZMmRIhca6J02axIsvvlioKuW6det4+OGHAWjfvj2tW7dm//79F93vgQMHFpQFds4xfvx41q1bR0xMDF9++SUnTpwoNhtWjx49aN7cNxlR/lSDPXr0KLN08ciRIwG4+eabOX78eLH6NKtWrWLfvn0Fy99++y3Z2dnUr189w8a1OtAroxcJjnOOiRMnct999xVbt3XrVpYtW8bEiRMZOHBg0DMi3XzzzTzzzDNs3Lix0PtUpcASyu+++y5ZWVls27aN2NhYEhMTSyw/XLS0stfrLbd0cTDlhzdv3kzdunWr6tQqpNbfjFVGL1Jc0TLFgwYN4u233y7IVI8dO8bx48fJyMigQYMGjBo1iieeeIJt27aVuH9pnn76af7zP/+zYPlHP/pRQdni/fv3c/ToUa6//vqgj1eW/FLLsbGxrFy5kmPHjgW9b3mli//0pz8B8Mknn3DFFVcUq9Hfv3//gmEpoMSndEIpajL6rPNZjPlwTIX2OXbmGF2adQlRj0QiV2CZ4pSUFKZNm8bevXu58cYbAbjkkkt4//33OXjwIE8++SQxMTHExcXx1ltvAb5SwSkpKTRv3rzEm7H5Bg8eXDBLFMCDDz7I/fffT+fOnYmNjWXOnDnUq1ePfv36MXXqVJKSkoK+GVvUz3/+c37605+SnJxM165dC+ZxDfbvI790cevWrYuVLr700kvp2bMnp0+fZvbs2cX2nz59Og888ACzZ8/G6/XSr1+/QoE/1KKmTPHpnNNMXj+5/A2L+Enbn/Dj1j+u8H4ioaQyxVKWipYpjpqMvlHdRrzW97Vwd0NEpMap1WP0IiK1gQK9SA1V04ZVpWa4mH8XCvQiNVB8fDwnT55UsJdCnHOcPHmS+Pj4Cu0XNWP0ItEkMTGR9PR0MjMzw90VqWHi4+NJTEys0D4K9CI1UFxcHG3btg13NyRKaOhGRCTKKdCLiEQ5BXoRkShX474Za2aZwBeVOEQCcKKKuhMpauM5Q+0879p4zlA7z7ui59zaOdespBU1LtBXlpmllvY14GhVG88Zaud518Zzhtp53lV5zhq6ERGJcgr0IiJRLhoD/YxwdyAMauM5Q+0879p4zlA7z7vKzjnqxuhFRKSwaMzoRUQkgAK9iEiUi5pAb2a3mNk+MztoZhPC3Z9QMbOWZrbGzPaa2W4ze9Tf/j0zW2lmB/x/Ngl3X6uamdUxs+1m9lf/clsz2+Q/5z+ZWXhmXg4hM2tsZgvN7DP/Nb8x2q+1mf3K/297l5nNM7P4aLzWZva2mR03s10BbSVeW/P5nT++7TSzrhV5r6gI9GZWB5gOpAAdgZFm1jG8vQoZL/C4c64D0AN4yH+uE4CPnXPtgI/9y9HmUWBvwPKrwP/4z/lb4Jdh6VVo/RZY7pxrD3TBd/5Re63NrAXwCJDsnOsE1AHuJDqv9RzgliJtpV3bFKCd/2cs8FZF3igqAj3QDTjonDvsnMsB5gNDw9ynkHDOfeWc2+Z/fRrff/wW+M73Hf9m7wDDwtPD0DCzROAnwEz/sgE3Awv9m0TjOV8K/AiYBeCcy3HOnSLKrzW+qrr1zSwWaAB8RRRea+fcWuCbIs2lXduhwLvOZyPQ2MyaB/te0RLoWwBfBiyn+9uimpm1AW4ANgFXOOe+At+HAXB5+HoWEq8DvwEu+JebAqecc17/cjRe86uBTGC2f8hqppk1JIqvtXPuGPBfwFF8AT4L2Er0X+t8pV3bSsW4aAn0VkJbVD83amaXAB8Ajznn/h3u/oSSmQ0BjjvntgY2l7BptF3zWKAr8JZz7gbgLFE0TFMS/5j0UKAtcBXQEN+wRVHRdq3LU6l/79ES6NOBlgHLiUBGmPoScmYWhy/Iz3XO/dnf/HX+r3L+P4+Hq38h0Au41cyO4BuWuxlfht/Y/+s9ROc1TwfSnXOb/MsL8QX+aL7W/YHPnXOZzrlc4M9AT6L/Wucr7dpWKsZFS6DfArTz35mvi+/mzdIw9ykk/GPTs4C9zrnXAlYtBcb4X48BllR330LFOTfROZfonGuD79quds7dDawBRvg3i6pzBnDO/Qv40syu9zf9GNhDFF9rfEM2Pcysgf/fev45R/W1DlDatV0KjPY/fdMDyMof4gmKcy4qfoDBwH7gEPB0uPsTwvPsje9Xtp1Amv9nML4x64+BA/4/vxfuvobo/PsCf/W/vhrYDBwE/h9QL9z9C8H5JgGp/uu9GGgS7dcaeB74DNgFvAfUi8ZrDczDdx8iF1/G/svSri2+oZvp/vj2Kb6nkoJ+L5VAEBGJctEydCMiIqVQoBcRiXIK9CIiUU6BXkQkyinQi4hEOQV6EZEop0AvIhLl/j9nIE0oslP6rgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_1.history['accuracy'], label = \"tarina Trainable\")\n",
    "plt.plot(history_1.history['val_accuracy'], label = \"test Trainable\")\n",
    "\n",
    "plt.plot(history_2.history['accuracy'], label = \"tarina Not Trainable\")\n",
    "plt.plot(history_2.history['val_accuracy'], label = \"test Not Trainable\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
